{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBLbL+5iX7mZ3nDdzZtUfv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahyuozorahmanurung/adaboost-dan-gradient-adaboost/blob/main/ML_adaboost_dan_gradient_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cdy7io7uw9ZA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def accuracy(y, pred):\n",
        "    return np.sum(y == pred) / float(len(y))\n",
        "\n",
        "\n",
        "def parse_spambase_data(filename=\"spambase.train\"):\n",
        "    \"\"\"\n",
        "    Given a \"spambase.train\" return X and Y numpy arrays\n",
        "\n",
        "    X is of size number of rows x num_features\n",
        "    Y is an array of size the number of rows\n",
        "    Y is the last element of each row. (Convert 0 to -1)\n",
        "    \"\"\"\n",
        "    p = Path(\"spambase.train\")\n",
        "    data = p.read_text().split(\"\\n\")\n",
        "    data.remove(\"\")\n",
        "\n",
        "    X = np.zeros((len(data), len(data[0].split(\",\")) - 1))\n",
        "    Y = np.zeros((len(data),))\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        row = data[i].split(\",\")\n",
        "        for j in range(len(row)):\n",
        "            if j != len(row) - 1:\n",
        "                X[i][j] = np.float64(row[j])\n",
        "            else:\n",
        "                Y[i] = -1 if int(row[j]) == 0 else 1\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def adaboost(X, y, num_iter, max_depth=1):\n",
        "    \"\"\"\n",
        "    Given an numpy matrix X, a array y and num_iter return trees and weights\n",
        "\n",
        "    Input: X, y, num_iter\n",
        "    Outputs: array of trees from DecisionTreeClassifier\n",
        "             trees_weights array of floats\n",
        "\n",
        "    Assumes y is {-1, 1}\n",
        "    \"\"\"\n",
        "    trees = []\n",
        "    trees_weights = []\n",
        "    N, _ = X.shape\n",
        "    d = np.ones(N) / N\n",
        "\n",
        "    w = d\n",
        "    for m in range(num_iter):\n",
        "        h = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
        "        h.fit(X, y, sample_weight=w)\n",
        "        y_pred = h.predict(X)\n",
        "\n",
        "        trees.append(h)\n",
        "\n",
        "        err = np.sum(w * (y_pred != y)) / np.sum(w)\n",
        "        alpha = np.log((1 - err) / err)\n",
        "        w *= np.exp(alpha * (y_pred != y))\n",
        "        trees_weights.append(alpha)\n",
        "\n",
        "    return trees, trees_weights\n",
        "\n",
        "\n",
        "def adaboost_predict(X, trees, trees_weights):\n",
        "    \"\"\"\n",
        "    Given X, trees and weights predict Y\n",
        "    \"\"\"\n",
        "    # X input, y output\n",
        "    N, _ = X.shape\n",
        "    y = np.zeros(N)\n",
        "\n",
        "    preds = []\n",
        "    for i in range(len(trees)):\n",
        "        y_pred = trees[i].predict(X)\n",
        "        preds.append(trees_weights[i] * y_pred)\n",
        "    y = np.sign(np.sum(preds, axis=0))\n",
        "\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADABOOST**"
      ],
      "metadata": {
        "id": "EdQXe669xdXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "X, y = parse_spambase_data(\"spambase.train\")\n",
        "X_test, y_test = parse_spambase_data(\"spambase.test\")\n",
        "\n",
        "# Create the base estimator\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Train the AdaBoost ensemble\n",
        "num_iter = 10\n",
        "model = AdaBoostClassifier(estimator=base_estimator, n_estimators=num_iter)  # Use 'estimator' instead of 'base_estimator'\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions using the trained ensemble\n",
        "y_hat = model.predict(X)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the training set\n",
        "acc_train = accuracy_score(y, y_hat)\n",
        "\n",
        "# Calculate accuracy for the test set\n",
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracies\n",
        "print(\"Train Accuracy: %.4f\" % acc_train)\n",
        "print(\"Test Accuracy: %.4f\" % acc_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNzj9_hgxL1o",
        "outputId": "a25be3b3-3c34-423b-b44d-a95f1c666c7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9211\n",
            "Test Accuracy: 0.9211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRADIENTBOOSTING**"
      ],
      "metadata": {
        "id": "B9MXpzgaxzo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradient_boosting_mse\n",
        "\n",
        "# Load the dataset\n",
        "X, y = gradient_boosting_mse.load_dataset(\"tiny.rent.train\")\n",
        "X_test, y_test = gradient_boosting_mse.load_dataset(\"tiny.rent.test\")\n",
        "\n",
        "# Check if datasets were loaded correctly\n",
        "if X is None or y is None:\n",
        "    raise ValueError(\"Training dataset could not be loaded.\")\n",
        "if X_test is None or y_test is None:\n",
        "    raise ValueError(\"Test dataset could not be loaded.\")\n",
        "\n",
        "# Train the Gradient Boosting ensemble\n",
        "num_iter = 10  # Number of boosting iterations\n",
        "max_depth = 1  # Maximum depth of each tree\n",
        "nu = 0.1      # Learning rate\n",
        "\n",
        "# Train the model\n",
        "y_mean, trees = gradient_boosting_mse.gradient_boosting_mse(X, y, num_iter, max_depth, nu)\n",
        "\n",
        "# Make predictions using the trained ensemble\n",
        "y_hat = gradient_boosting_mse.gradient_boosting_predict(X, trees, y_mean, nu)\n",
        "y_hat_test = gradient_boosting_mse.gradient_boosting_predict(X_test, trees, y_mean, nu)\n",
        "\n",
        "# Calculate R2 Score for the training set\n",
        "r2_train = gradient_boosting_mse.r2_score(y, y_hat)\n",
        "\n",
        "# Calculate R2 Score for the test set\n",
        "r2_test = gradient_boosting_mse.r2_score(y_test, y_hat_test)\n",
        "\n",
        "# Print the R2 Scores\n",
        "print(\"Train R2 Score: %.4f\" % r2_train)\n",
        "print(\"Test R2 Score: %.4f\" % r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnPLw2d2xQTq",
        "outputId": "f2f399f1-5a4e-486c-c80b-6bdd64f90b4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train R2 Score: 0.6466\n",
            "Test R2 Score: 0.5297\n"
          ]
        }
      ]
    }
  ]
}